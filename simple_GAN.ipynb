{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4ydBTz1txhCe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, dim_img):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        nn.Linear(dim_img, 128),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(128, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.disc(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim, dim_img):\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        nn.Linear(z_dim, 256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(256, dim_img),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.gen(x)\n"
      ],
      "metadata": {
        "id": "RpbHCISKyFC6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "TrUROzAK1nLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 3e-4\n",
        "z_dim = 64\n",
        "image_dim = 28*28*1\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "step = 0\n",
        "\n",
        "disc = Discriminator(image_dim).to(device)\n",
        "gen = Generator(z_dim, image_dim).to(device)\n",
        "\n",
        "optim_disc = optim.Adam(disc.parameters(), lr=lr)\n",
        "optim_gen = optim.Adam(gen.parameters(), lr=lr)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
        "writer_fake = SummaryWriter(f'runs/GAN_MNIST/fake')\n",
        "writer_real = SummaryWriter(f'runs/GAN_MNIST/real')"
      ],
      "metadata": {
        "id": "LrrARdDyzu_O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "mW-Yp5Ah2lAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "dataset = datasets.MNIST(root='dataset/', transform=transform, download=True)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "R60AZbUu2TFG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traning"
      ],
      "metadata": {
        "id": "h0-tXsdWLW93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch_idx, (real, _) in enumerate(loader):\n",
        "    real = real.view(-1, 784).to(device)\n",
        "    batch_size = real.shape[0]\n",
        "\n",
        "    noise = torch.randn(batch_size, z_dim).to(device)\n",
        "    fake = gen(noise)\n",
        "\n",
        "    disc_real = disc(real).view(-1)\n",
        "    loss_disc_real = loss_fn(disc_real, torch.ones_like(disc_real))\n",
        "    disc_fake = disc(fake).view(-1)\n",
        "    loss_disc_fake = loss_fn(disc_fake, torch.zeros_like(disc_fake))\n",
        "    loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
        "\n",
        "    disc.zero_grad()\n",
        "    loss_disc.backward(retain_graph=True)\n",
        "    optim_disc.step()\n",
        "\n",
        "    output = disc(fake).view(-1)\n",
        "    loss_gen = loss_fn(output, torch.ones_like(output))\n",
        "    gen.zero_grad()\n",
        "    loss_gen.backward()\n",
        "    optim_gen.step()\n",
        "\n",
        "    if batch_idx == 0:\n",
        "      print(\n",
        "          f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
        "                Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
        "      )\n",
        "\n",
        "      with torch.no_grad():\n",
        "          fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
        "          data = real.reshape(-1, 1, 28, 28)\n",
        "          img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
        "          img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
        "\n",
        "          writer_fake.add_image(\n",
        "              \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
        "          )\n",
        "          writer_real.add_image(\n",
        "              \"Mnist Real Images\", img_grid_real, global_step=step\n",
        "          )\n",
        "          step += 1"
      ],
      "metadata": {
        "id": "XCjfINSB2-sh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1d3aad-09d6-4297-f2de-999f4719ff6b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/50] Batch 0/1875                 Loss D: 0.6792, loss G: 0.7016\n",
            "Epoch [1/50] Batch 0/1875                 Loss D: 0.6110, loss G: 0.9259\n",
            "Epoch [2/50] Batch 0/1875                 Loss D: 0.8985, loss G: 0.8038\n",
            "Epoch [3/50] Batch 0/1875                 Loss D: 0.6823, loss G: 0.8772\n",
            "Epoch [4/50] Batch 0/1875                 Loss D: 0.5659, loss G: 0.9544\n",
            "Epoch [5/50] Batch 0/1875                 Loss D: 0.7036, loss G: 0.8397\n",
            "Epoch [6/50] Batch 0/1875                 Loss D: 0.6986, loss G: 1.1053\n",
            "Epoch [7/50] Batch 0/1875                 Loss D: 0.4132, loss G: 1.4153\n",
            "Epoch [8/50] Batch 0/1875                 Loss D: 0.3886, loss G: 1.3847\n",
            "Epoch [9/50] Batch 0/1875                 Loss D: 0.4367, loss G: 1.7541\n",
            "Epoch [10/50] Batch 0/1875                 Loss D: 0.7652, loss G: 1.1256\n",
            "Epoch [11/50] Batch 0/1875                 Loss D: 0.9415, loss G: 0.7985\n",
            "Epoch [12/50] Batch 0/1875                 Loss D: 0.5282, loss G: 1.0730\n",
            "Epoch [13/50] Batch 0/1875                 Loss D: 0.9054, loss G: 0.7717\n",
            "Epoch [14/50] Batch 0/1875                 Loss D: 0.7470, loss G: 1.0400\n",
            "Epoch [15/50] Batch 0/1875                 Loss D: 0.6608, loss G: 1.1241\n",
            "Epoch [16/50] Batch 0/1875                 Loss D: 0.6323, loss G: 1.0717\n",
            "Epoch [17/50] Batch 0/1875                 Loss D: 0.5000, loss G: 1.2479\n",
            "Epoch [18/50] Batch 0/1875                 Loss D: 0.7175, loss G: 0.9113\n",
            "Epoch [19/50] Batch 0/1875                 Loss D: 0.5201, loss G: 1.2250\n",
            "Epoch [20/50] Batch 0/1875                 Loss D: 0.5869, loss G: 1.3245\n",
            "Epoch [21/50] Batch 0/1875                 Loss D: 0.5651, loss G: 0.9829\n",
            "Epoch [22/50] Batch 0/1875                 Loss D: 0.7385, loss G: 1.0755\n",
            "Epoch [23/50] Batch 0/1875                 Loss D: 0.7790, loss G: 1.1636\n",
            "Epoch [24/50] Batch 0/1875                 Loss D: 0.6328, loss G: 1.2356\n",
            "Epoch [25/50] Batch 0/1875                 Loss D: 0.5693, loss G: 1.0678\n",
            "Epoch [26/50] Batch 0/1875                 Loss D: 0.5606, loss G: 1.6099\n",
            "Epoch [27/50] Batch 0/1875                 Loss D: 0.6404, loss G: 0.9784\n",
            "Epoch [28/50] Batch 0/1875                 Loss D: 0.5531, loss G: 1.6703\n",
            "Epoch [29/50] Batch 0/1875                 Loss D: 0.4927, loss G: 1.2938\n",
            "Epoch [30/50] Batch 0/1875                 Loss D: 0.6226, loss G: 1.0695\n",
            "Epoch [31/50] Batch 0/1875                 Loss D: 0.6830, loss G: 1.1941\n",
            "Epoch [32/50] Batch 0/1875                 Loss D: 0.4705, loss G: 1.3406\n",
            "Epoch [33/50] Batch 0/1875                 Loss D: 0.6275, loss G: 1.1677\n",
            "Epoch [34/50] Batch 0/1875                 Loss D: 0.5305, loss G: 1.1256\n",
            "Epoch [35/50] Batch 0/1875                 Loss D: 0.5353, loss G: 1.0203\n",
            "Epoch [36/50] Batch 0/1875                 Loss D: 0.6495, loss G: 0.9097\n",
            "Epoch [37/50] Batch 0/1875                 Loss D: 0.6137, loss G: 0.9597\n",
            "Epoch [38/50] Batch 0/1875                 Loss D: 0.6754, loss G: 1.0933\n",
            "Epoch [39/50] Batch 0/1875                 Loss D: 0.7580, loss G: 0.7699\n",
            "Epoch [40/50] Batch 0/1875                 Loss D: 0.6035, loss G: 0.9866\n",
            "Epoch [41/50] Batch 0/1875                 Loss D: 0.5922, loss G: 0.9362\n",
            "Epoch [42/50] Batch 0/1875                 Loss D: 0.6553, loss G: 1.3233\n",
            "Epoch [43/50] Batch 0/1875                 Loss D: 0.6745, loss G: 0.9617\n",
            "Epoch [44/50] Batch 0/1875                 Loss D: 0.6735, loss G: 1.0232\n",
            "Epoch [45/50] Batch 0/1875                 Loss D: 0.5834, loss G: 0.9881\n",
            "Epoch [46/50] Batch 0/1875                 Loss D: 0.6230, loss G: 0.9352\n",
            "Epoch [47/50] Batch 0/1875                 Loss D: 0.6504, loss G: 1.0090\n",
            "Epoch [48/50] Batch 0/1875                 Loss D: 0.6776, loss G: 0.7588\n",
            "Epoch [49/50] Batch 0/1875                 Loss D: 0.7363, loss G: 0.8349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jGX8TrA8Li1u"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}